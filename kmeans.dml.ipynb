{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:25:44.368939Z",
     "start_time": "2025-03-03T22:25:43.451896Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_csv(file):\n",
    "    return pd.read_csv(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:25:49.225763Z",
     "start_time": "2025-03-03T22:25:49.222452Z"
    }
   },
   "id": "3132d76ba44c9195",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;34mexperiments\u001B[0m/  kmeans.dml.ipynb\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2458273, 378)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ls\n",
    "# Step 1: Read all CSV files into a single DataFrame\n",
    "file_paths = glob.glob(\"experiments/data/census/train_census_enc.csv/*\")  # Adjust the pattern as needed\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    df_list = list(executor.map(load_csv, file_paths))\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T20:16:01.289756Z",
     "start_time": "2025-03-03T20:15:31.584294Z"
    }
   },
   "id": "31a4d09d5054357e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['experiments/data/census/train_census_enc.csv/0-m-00009',\n 'experiments/data/census/train_census_enc.csv/0-m-00006',\n 'experiments/data/census/train_census_enc.csv/0-m-00011',\n 'experiments/data/census/train_census_enc.csv/0-m-00001',\n 'experiments/data/census/train_census_enc.csv/0-m-00002',\n 'experiments/data/census/train_census_enc.csv/0-m-00000',\n 'experiments/data/census/train_census_enc.csv/0-m-00005',\n 'experiments/data/census/train_census_enc.csv/0-m-00004',\n 'experiments/data/census/train_census_enc.csv/0-m-00010',\n 'experiments/data/census/train_census_enc.csv/0-m-00008',\n 'experiments/data/census/train_census_enc.csv/0-m-00007',\n 'experiments/data/census/train_census_enc.csv/0-m-00003']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T20:16:13.952873Z",
     "start_time": "2025-03-03T20:16:13.947634Z"
    }
   },
   "id": "286b26eb117ab996",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing (Handle missing values, standardize)\n",
    "#df = df.dropna()  # Remove missing values (or handle differently)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)  # Normalize features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:30:51.942785Z",
     "start_time": "2025-02-28T07:30:49.926607Z"
    }
   },
   "id": "e2423389de21c6a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 214910817.4941845.\n",
      "Iteration 1, inertia 158307702.60867172.\n",
      "Iteration 2, inertia 152534502.57173908.\n",
      "Iteration 3, inertia 150436712.24376184.\n",
      "Iteration 4, inertia 149325912.2557903.\n",
      "Iteration 5, inertia 148117296.79167384.\n",
      "Iteration 6, inertia 146889139.31222188.\n",
      "Iteration 7, inertia 146544900.119735.\n",
      "Iteration 8, inertia 146448517.68799174.\n",
      "Iteration 9, inertia 146327097.3923279.\n",
      "Iteration 10, inertia 146154178.81179875.\n",
      "Iteration 11, inertia 145912827.7683926.\n",
      "Iteration 12, inertia 145579443.94535673.\n",
      "Iteration 13, inertia 145493195.95616245.\n",
      "Iteration 14, inertia 145487311.470254.\n",
      "Iteration 15, inertia 145484565.16992974.\n",
      "Iteration 16, inertia 145482886.30261904.\n",
      "Iteration 17, inertia 145481744.17636025.\n",
      "Iteration 18, inertia 145481096.53001603.\n",
      "Iteration 19, inertia 145480792.16373014.\n",
      "Iteration 20, inertia 145480709.32047847.\n",
      "Iteration 21, inertia 145480690.05050677.\n",
      "Iteration 22, inertia 145480683.85522068.\n",
      "Iteration 23, inertia 145480682.171325.\n",
      "Iteration 24, inertia 145480681.4207549.\n",
      "Iteration 25, inertia 145480681.0562838.\n",
      "Iteration 26, inertia 145480680.91142333.\n",
      "Iteration 27, inertia 145480680.83033222.\n",
      "[[-0.2933601  -0.17134945  0.1218031  ... -1.43802779  0.35689781\n",
      "   2.6609788 ]\n",
      " [-0.30504712  0.28125389  0.13277098 ...  0.2097458  -0.2036399\n",
      "  -0.03755995]\n",
      " [ 0.26467508  0.16054641  0.25888277 ...  0.2109431  -0.20349986\n",
      "  -0.04078654]\n",
      " ...\n",
      " [ 0.11886712  0.27751963  0.27415196 ...  0.22362506 -0.21570829\n",
      "  -0.04329889]\n",
      " [-0.19777171  0.16443092  0.06103439 ... -0.00772219  0.01903463\n",
      "  -0.02529878]\n",
      " [ 0.51946985 -0.15618399  0.02018935 ...  0.2556705  -0.24468321\n",
      "  -0.053981  ]]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Apply K-Means Clustering\n",
    "k = 16  # Choose the number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, max_iter=28, tol=1e-17, verbose=True)\n",
    "kmeans.fit(df_scaled)\n",
    "print(kmeans.cluster_centers_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:34:50.481137Z",
     "start_time": "2025-02-28T07:34:44.355707Z"
    }
   },
   "id": "497671bdf26a6ccb",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_id = 0\n",
    "stats_per_run = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:26:01.606492Z",
     "start_time": "2025-03-03T22:26:01.603610Z"
    }
   },
   "id": "f3a2b080cdb25756",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Reading': 25600.95548200002,\n 'Concat': 1531.5822889999708,\n 'Scaling': 8705.232496000008,\n 'Kmeans': 24391.446082000017,\n 'Total': 60229.21634900001}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = {}\n",
    "start = time.perf_counter()\n",
    "file_paths = glob.glob(\"experiments/data/census/train_census_enc.csv/*\")\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    df_list = list(executor.map(load_csv, file_paths))\n",
    "t0 = time.perf_counter() \n",
    "stats[\"Reading\"] = (t0- start)*1000\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "t1 = time.perf_counter() \n",
    "stats[\"Concat\"] =  (t1 - t0)*1000\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)  # Normalize features\n",
    "t2 = time.perf_counter() \n",
    "stats[\"Scaling\"] =  (t2 - t1)*1000\n",
    "k = 16  # Choose the number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, max_iter=28, tol=1e-17, verbose=False)\n",
    "kmeans.fit(df_scaled)\n",
    "t3 = time.perf_counter() \n",
    "stats[\"Kmeans\"] = (t3 - t2)*1000\n",
    "stats[\"Total\"] = (t3 - start)*1000\n",
    "stats_per_run[str(run_id) + \"_\" + str(k)] = stats\n",
    "run_id += 1\n",
    "stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:31:22.922059Z",
     "start_time": "2025-03-03T22:30:22.687120Z"
    }
   },
   "id": "f9ae20c5e422fbba",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'0_16': {'Reading': 37600.20683299999,\n  'Concat': 1538.2471089999967,\n  'Scaling': 8690.557845000001,\n  'Kmeans': 25011.119250000007,\n  'Total': 72840.13103699998},\n '1_16': {'Reading': 31060.696595000023,\n  'Concat': 1529.7703019999744,\n  'Scaling': 9140.093003999993,\n  'Kmeans': 25165.067292999993,\n  'Total': 66895.62719399999},\n '2_16': {'Reading': 25600.95548200002,\n  'Concat': 1531.5822889999708,\n  'Scaling': 8705.232496000008,\n  'Kmeans': 24391.446082000017,\n  'Total': 60229.21634900001}}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_per_run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:32:04.952725Z",
     "start_time": "2025-03-03T22:32:04.947760Z"
    }
   },
   "id": "a3cc9e555dfc8067",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a24ffd13f90ff0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
